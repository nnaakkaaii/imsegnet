{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nakai-yu/dev/imsegnet/.venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "import shutil\n",
    "import zipfile\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import torchmetrics\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from albumentations import (HorizontalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise)\n",
    "from albumentations.pytorch import ToTensorV2 as ToTensor\n",
    "from PIL import Image\n",
    "from skimage import io, transform\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms, utils\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "TRAIN_PATH = '../data/stage1_train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像データ拡張の関数\n",
    "def get_train_transform():\n",
    "   return A.Compose(\n",
    "       [\n",
    "        # リサイズ(こちらはすでに適用済みなのでなくても良いです)\n",
    "        A.Resize(256, 256),\n",
    "        # 正規化(こちらの細かい値はalbumentations.augmentations.transforms.Normalizeのデフォルトの値を適用)\n",
    "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        # 水平フリップ（pはフリップする確率）\n",
    "        A.HorizontalFlip(p=0.25),\n",
    "        # 垂直フリップ\n",
    "        A.VerticalFlip(p=0.25),\n",
    "        ToTensor()\n",
    "        ])\n",
    "\n",
    "# Datasetクラスの定義\n",
    "class LoadDataSet(Dataset):\n",
    "    WIDTH = 256\n",
    "    HEIGHT = 256\n",
    "\n",
    "    def __init__(self, path, transform=None):\n",
    "        self.path = path\n",
    "        self.folders = os.listdir(path)\n",
    "        self.transforms = get_train_transform()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.folders)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_folder = os.path.join(self.path, self.folders[idx], 'images/')\n",
    "        mask_folder = os.path.join(self.path, self.folders[idx], 'masks/')\n",
    "        image_path = os.path.join(image_folder, os.listdir(image_folder)[0])\n",
    "\n",
    "        # 画像データの取得\n",
    "        img = io.imread(image_path)[:, :, :3].astype('float32')\n",
    "        img = transform.resize(img, (self.WIDTH, self.HEIGHT))\n",
    "\n",
    "        mask = self.get_mask(mask_folder, self.WIDTH, self.HEIGHT).astype('float32')\n",
    "\n",
    "        augmented = self.transforms(image=img, mask=mask)\n",
    "\n",
    "        img = augmented['image']\n",
    "        mask = augmented['mask']\n",
    "\n",
    "        mask = mask.permute(2, 0, 1)\n",
    "        point = self.get_point()\n",
    "\n",
    "        label = mask[:, point[0], point[1]]\n",
    "        point = torch.tensor([point], dtype=torch.int64)\n",
    "\n",
    "        return img, point, label\n",
    "\n",
    "    def get_mask(self, mask_folder, IMG_HEIGHT, IMG_WIDTH):\n",
    "        mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=np.bool_)\n",
    "        for mask_ in os.listdir(mask_folder):\n",
    "                mask_ = io.imread(os.path.join(mask_folder, mask_))\n",
    "                mask_ = transform.resize(mask_, (IMG_HEIGHT, IMG_WIDTH))\n",
    "                mask_ = np.expand_dims(mask_, axis=-1)\n",
    "                mask = np.maximum(mask, mask_)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def get_point(self):\n",
    "        x = random.randint(0, self.WIDTH - 1)\n",
    "        y = random.randint(0, self.HEIGHT - 1)\n",
    "        return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = LoadDataSet(TRAIN_PATH, transform=get_train_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "torch.Size([1, 2])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "image, point, label = train_dataset.__getitem__(0)\n",
    "print(image.shape)\n",
    "print(point.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "670"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image(img):\n",
    "    img = np.array(np.transpose(img, (1, 2, 0)))\n",
    "    # 下は画像拡張での正規化を元に戻しています\n",
    "    mean = np.array((0.485, 0.456, 0.406))\n",
    "    std = np.array((0.229, 0.224, 0.225))\n",
    "    img = std * img + mean\n",
    "    img = img * 255\n",
    "    img = img.astype(np.uint8)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train data: 502\n",
      "Length of validation data: 168\n"
     ]
    }
   ],
   "source": [
    "split_ratio = 0.25\n",
    "train_size=int(np.round(train_dataset.__len__() * (1 - split_ratio), 0))\n",
    "valid_size=int(np.round(train_dataset.__len__() * split_ratio, 0))\n",
    "train_data, valid_data = random_split(train_dataset, [train_size, valid_size])\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(dataset=valid_data, batch_size=10)\n",
    "\n",
    "print(\"Length of train data: {}\".format(len(train_data)))\n",
    "print(\"Length of validation data: {}\".format(len(valid_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super().__init__()\n",
    "        # 資料中の『FCN』に当たる部分\n",
    "        self.conv1 = conv_bn_relu(input_channels,64)\n",
    "        self.conv2 = conv_bn_relu(64, 128)\n",
    "        self.conv3 = conv_bn_relu(128, 256)\n",
    "        self.conv4 = conv_bn_relu(256, 512)\n",
    "        self.conv5 = conv_bn_relu(512, 1024)\n",
    "        self.down_pooling = nn.MaxPool2d(2)\n",
    "\n",
    "        # 資料中の『Up Sampling』に当たる部分\n",
    "        self.up_pool6 = up_pooling(1024, 512)\n",
    "        self.conv6 = conv_bn_relu(1024, 512)\n",
    "        self.up_pool7 = up_pooling(512, 256)\n",
    "        self.conv7 = conv_bn_relu(512, 256)\n",
    "        self.up_pool8 = up_pooling(256, 128)\n",
    "        self.conv8 = conv_bn_relu(256, 128)\n",
    "        self.up_pool9 = up_pooling(128, 64)\n",
    "        self.conv9 = conv_bn_relu(128, 64)\n",
    "        self.conv10 = nn.Conv2d(64, output_channels, 1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight.data, a=0, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, points):\n",
    "        # 正規化\n",
    "        x = x/255.\n",
    "\n",
    "        # 資料中の『FCN』に当たる部分\n",
    "        x1 = self.conv1(x)\n",
    "        p1 = self.down_pooling(x1)\n",
    "        x2 = self.conv2(p1)\n",
    "        p2 = self.down_pooling(x2)\n",
    "        x3 = self.conv3(p2)\n",
    "        p3 = self.down_pooling(x3)\n",
    "        x4 = self.conv4(p3)\n",
    "        p4 = self.down_pooling(x4)\n",
    "        x5 = self.conv5(p4)\n",
    "\n",
    "        # 資料中の『Up Sampling』に当たる部分, torch.catによりSkip Connectionをしている\n",
    "        p6 = self.up_pool6(x5)\n",
    "        x6 = torch.cat([p6, x4], dim=1)\n",
    "        x6 = self.conv6(x6)\n",
    "\n",
    "        p7 = self.up_pool7(x6)\n",
    "        x7 = torch.cat([p7, x3], dim=1)\n",
    "        x7 = self.conv7(x7)\n",
    "\n",
    "        p8 = self.up_pool8(x7)\n",
    "        x8 = torch.cat([p8, x2], dim=1)\n",
    "        x8 = self.conv8(x8)\n",
    "\n",
    "        p9 = self.up_pool9(x8)\n",
    "        x9 = torch.cat([p9, x1], dim=1)\n",
    "        x9 = self.conv9(x9)\n",
    "\n",
    "        output = self.conv10(x9)\n",
    "\n",
    "        b, c, h, w = output.shape\n",
    "        index = (points[:, :, 0] + w * points[:, :, 1]).unsqueeze(2)\n",
    "        pred = output.reshape(b, c, h * w).gather(2, index).squeeze(2)\n",
    "\n",
    "        return pred\n",
    "\n",
    "\n",
    "def conv_bn_relu(in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "    return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "def down_pooling():\n",
    "    return nn.MaxPool2d(2)\n",
    "\n",
    "def up_pooling(in_channels, out_channels, kernel_size=2, stride=2):\n",
    "    return nn.Sequential(\n",
    "        # 転置畳み込み\n",
    "        nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride),\n",
    "        nn.BatchNorm2d(out_channels),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1]) torch.Size([10, 1])\n",
      "tensor([[ 7.8754],\n",
      "        [ 5.9705],\n",
      "        [ 0.1203],\n",
      "        [ 5.6463],\n",
      "        [ 6.8848],\n",
      "        [-1.3436],\n",
      "        [ 6.7791],\n",
      "        [ 3.5101],\n",
      "        [ 1.4560],\n",
      "        [ 2.5458]], grad_fn=<SqueezeBackward1>) tensor([[0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.0000],\n",
      "        [0.1186],\n",
      "        [0.0066],\n",
      "        [1.0000]])\n"
     ]
    }
   ],
   "source": [
    "def test_unet():\n",
    "    model = UNet(3, 1)\n",
    "    x, p, t = next(iter(train_loader))\n",
    "    y = model(x, p)\n",
    "    print(y.shape, t.shape)\n",
    "    print(y, t)\n",
    "    return\n",
    "\n",
    "test_unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss: 5.147805213928223, IoU: 0.5: 100%|██████████| 51/51 [02:44<00:00,  3.22s/it]                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.2554461190513535, Train IOU: 0.7470588239968992\n",
      "Valid Loss: 0.6106826531536439, Valid IOU: 0.8338235231006846\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 0.6553490161895752, IoU: 0.5: 100%|██████████| 51/51 [02:05<00:00,  2.46s/it]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8757495956093657, Train IOU: 0.8058823475650713\n",
      "Valid Loss: 0.6413560759495286, Valid IOU: 0.8985294103622437\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3, loss: 0.03526078909635544, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.46s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5733212412280195, Train IOU: 0.8607843062456917\n",
      "Valid Loss: 0.5508027015363469, Valid IOU: 0.8691176386440501\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 0.17650499939918518, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.46s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.47124496905827057, Train IOU: 0.8686274453705433\n",
      "Valid Loss: 0.6281522521201302, Valid IOU: 0.8529411729644326\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5, loss: 0.15712429583072662, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.46s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4543606989523944, Train IOU: 0.8745097950393078\n",
      "Valid Loss: 0.6156334596521714, Valid IOU: 0.8573529404752395\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 0.16861799359321594, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.46s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4760594350450179, Train IOU: 0.864705879314273\n",
      "Valid Loss: 0.5750580105711433, Valid IOU: 0.8279411757693571\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7, loss: 0.17399334907531738, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.45s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.45668286464962304, Train IOU: 0.8725490114268135\n",
      "Valid Loss: 0.47141002381549163, Valid IOU: 0.8573529404752395\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 1.2791695594787598, IoU: 0.5: 100%|██████████| 51/51 [02:03<00:00,  2.43s/it]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4466630531584515, Train IOU: 0.8725490161016876\n",
      "Valid Loss: 0.5044892469749731, Valid IOU: 0.8455882352941176\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9, loss: 0.13555502891540527, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.45s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4224110010500048, Train IOU: 0.8686274442018247\n",
      "Valid Loss: 0.3824085549396627, Valid IOU: 0.8970588235294118\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 0.4094507098197937, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.46s/it]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.45726272390753614, Train IOU: 0.8725490090893764\n",
      "Valid Loss: 0.4492317530162194, Valid IOU: 0.9029411708607393\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11, loss: 2.0090320110321045, IoU: 0.5: 100%|██████████| 51/51 [02:04<00:00,  2.44s/it]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5665649428379302, Train IOU: 0.8333333269053814\n",
      "Valid Loss: 0.4946618921616498, Valid IOU: 0.8544117597972646\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12, loss: 0.08109353482723236, IoU: 1.0: 100%|██████████| 51/51 [02:04<00:00,  2.44s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4035295972637102, Train IOU: 0.8921568522266313\n",
      "Valid Loss: 0.37977421327548866, Valid IOU: 0.8955882226719576\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13, loss: 1.1264389753341675, IoU: 0.5: 100%|██████████| 51/51 [02:05<00:00,  2.46s/it]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4641800341652889, Train IOU: 0.8666666640954859\n",
      "Valid Loss: 0.4859687011031544, Valid IOU: 0.8602941106347477\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14, loss: 0.17912383377552032, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.46s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4081304492611511, Train IOU: 0.8803921493829465\n",
      "Valid Loss: 0.41591571490554247, Valid IOU: 0.8882352850016426\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15, loss: 0.1645144522190094, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.47s/it]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4576927575410581, Train IOU: 0.8686274477079803\n",
      "Valid Loss: 0.5035043674356797, Valid IOU: 0.833823519594529\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 16, loss: 0.13467150926589966, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.47s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3898341683488266, Train IOU: 0.8882352861703611\n",
      "Valid Loss: 0.45051609417971444, Valid IOU: 0.8691176421502057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 17, loss: 0.14069905877113342, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.47s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.42486515758084314, Train IOU: 0.8803921540578207\n",
      "Valid Loss: 0.39226873219013214, Valid IOU: 0.8808823508374831\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 18, loss: 0.9484347105026245, IoU: 0.5: 100%|██████████| 51/51 [02:04<00:00,  2.44s/it]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4519154544846684, Train IOU: 0.8549019554082085\n",
      "Valid Loss: 0.43593404222937193, Valid IOU: 0.8632352843004114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 19, loss: 0.14521490037441254, IoU: 1.0: 100%|██████████| 51/51 [02:04<00:00,  2.43s/it]               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3877033432032548, Train IOU: 0.8980392054015515\n",
      "Valid Loss: 0.4077554910498507, Valid IOU: 0.8999999866766089\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 20, loss: 0.1698000133037567, IoU: 1.0: 100%|██████████| 51/51 [02:05<00:00,  2.47s/it]                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.43346985970057694, Train IOU: 0.8803921517203835\n",
      "Valid Loss: 0.3806152291157666, Valid IOU: 0.916176462874693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# <---------------各インスタンス作成---------------------->\n",
    "model = UNet(3,1).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "accuracy_metric = torchmetrics.Accuracy(threshold=0.5).to(device='cuda:0')\n",
    "num_epochs=20\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "checkpoint_path = 'model/chkpoint_'\n",
    "best_model_path = 'model/bestmodel.pt'\n",
    "\n",
    "total_train_loss = []\n",
    "total_train_score = []\n",
    "total_valid_loss = []\n",
    "total_valid_score = []\n",
    "\n",
    "losses_value = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # <---------------トレーニング---------------------->\n",
    "    train_loss = []\n",
    "    train_score = []\n",
    "    valid_loss = []\n",
    "    valid_score = []\n",
    "    pbar = tqdm(train_loader, desc = 'description')\n",
    "    for x_train, p_train, t_train in pbar:\n",
    "        x_train = torch.autograd.Variable(x_train).cuda()\n",
    "        p_train = torch.autograd.Variable(p_train).cuda()\n",
    "        t_train = torch.autograd.Variable(t_train).cuda()\n",
    "        optimizer.zero_grad()\n",
    "        y_train = model(x_train, p_train)\n",
    "        # 損失計算\n",
    "        loss = criterion(y_train, t_train)\n",
    "        losses_value = loss.item()\n",
    "        # 精度評価\n",
    "        score = accuracy_metric(y_train, t_train.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(losses_value)\n",
    "        train_score.append(score.item())\n",
    "        pbar.set_description(f\"Epoch: {epoch+1}, loss: {losses_value}, IoU: {score}\")\n",
    "\n",
    "    # <---------------評価---------------------->\n",
    "    with torch.no_grad():\n",
    "        for x_val, p_val, t_val in val_loader:\n",
    "            x_val = torch.autograd.Variable(x_val).cuda()\n",
    "            p_val = torch.autograd.Variable(p_val).cuda()\n",
    "            t_val = torch.autograd.Variable(t_val).cuda()\n",
    "            y_val = model(x_val, p_val)\n",
    "            # 損失計算\n",
    "            loss = criterion(y_val, t_val)\n",
    "            losses_value = loss.item()\n",
    "            # 精度評価\n",
    "            score = accuracy_metric(y_val, t_val.long())\n",
    "            valid_loss.append(losses_value)\n",
    "            valid_score.append(score.item())\n",
    "\n",
    "    total_train_loss.append(np.mean(train_loss))\n",
    "    total_train_score.append(np.mean(train_score))\n",
    "    total_valid_loss.append(np.mean(valid_loss))\n",
    "    total_valid_score.append(np.mean(valid_score))\n",
    "    print(f\"Train Loss: {total_train_loss[-1]}, Train IOU: {total_train_score[-1]}\")\n",
    "    print(f\"Valid Loss: {total_valid_loss[-1]}, Valid IOU: {total_valid_score[-1]}\")\n",
    "\n",
    "    checkpoint = {\n",
    "        'epoch': epoch + 1,\n",
    "        'valid_loss_min': total_valid_loss[-1],\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }\n",
    "\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(1)\n",
    "plt.figure(figsize=(15,5))\n",
    "sns.set_style(style=\"darkgrid\")\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.lineplot(x=range(1,num_epochs+1), y=total_train_loss, label=\"Train Loss\")\n",
    "sns.lineplot(x=range(1,num_epochs+1), y=total_valid_loss, label=\"Valid Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"DiceLoss\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.lineplot(x=range(1,num_epochs+1), y=total_train_score, label=\"Train Score\")\n",
    "sns.lineplot(x=range(1,num_epochs+1), y=total_valid_score, label=\"Valid Score\")\n",
    "plt.title(\"Score (IoU)\")\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predict(model, n_images):\n",
    "    figure, ax = plt.subplots(nrows=n_images, ncols=3, figsize=(15, 18))\n",
    "    with torch.no_grad():\n",
    "        for data,mask in val_loader:\n",
    "            data = torch.autograd.Variable(data, volatile=True).cuda()\n",
    "            mask = torch.autograd.Variable(mask, volatile=True).cuda()\n",
    "            o = model(data)\n",
    "            break\n",
    "    for img_no in range(0, n_images):\n",
    "        tm=o[img_no][0].data.cpu().numpy()\n",
    "        img = data[img_no].data.cpu()\n",
    "        msk = mask[img_no].data.cpu()\n",
    "        img = format_image(img)\n",
    "        msk = format_mask(msk)\n",
    "        ax[img_no, 0].imshow(img)\n",
    "        ax[img_no, 1].imshow(msk, interpolation=\"nearest\", cmap=\"gray\")\n",
    "        ax[img_no, 2].imshow(tm, interpolation=\"nearest\", cmap=\"gray\")\n",
    "        ax[img_no, 0].set_title(\"Input Image\")\n",
    "        ax[img_no, 1].set_title(\"Label Mask\")\n",
    "        ax[img_no, 2].set_title(\"Predicted Mask\")\n",
    "        ax[img_no, 0].set_axis_off()\n",
    "        ax[img_no, 1].set_axis_off()\n",
    "        ax[img_no, 2].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predict(model, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ac290080bb7a1b4650e412c63df3cbe039f928155369ccd9fe5b103f3311272"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
